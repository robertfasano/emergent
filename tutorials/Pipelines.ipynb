{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\emergent\\emergent\n",
      "Overwriting C:\\emergent/emergent/networks/test/things/test_thing.py\n",
      "Overwriting C:\\emergent/emergent/networks/test/hubs/test_hub.py\n",
      "Overwriting C:\\emergent/emergent/networks/test/network.py\n",
      "DataDict([('thing', {'X': 1.4, 'Y': 2})])\n",
      "New state: DataDict([('thing', {'X': 1, 'Y': 2})])\n",
      " * Serving Flask app \"emergent.API.API\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      "EMERGENT API\n"
     ]
    }
   ],
   "source": [
    "%run \"./Getting started.ipynb\"\n",
    "import requests\n",
    "base_url = 'http://localhost:6000'\n",
    "while True:\n",
    "    try:\n",
    "        r=requests.get(base_url)\n",
    "        if r.text == 'EMERGENT API':\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pipeline class allows us to combine multiple optimization processes into a single process. For example, we could do a coarse grid search to obtain an initial signal, then shrink the bounds to enclose the signal and sample with higher resolution, then finally fit all observed data to a model which predicts the location of the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Optimization complete!\n",
      "INFO:root:Time: 0s\n",
      "INFO:root:Evaluations: 113\n",
      "INFO:root:Improvement: 79.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29999998 0.60000001] -0.9999999999999958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting socketIO client.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emergent.pipeline import (Pipeline, Source, GridSearch, GaussianModel, Rescale, DifferentialEvolution, \n",
    "                              ParticleSwarm, GaussianProcess, GradientDescent, Adam, LBFGSB, Prune)\n",
    "from emergent.utilities.containers import DataDict\n",
    "\n",
    "''' Define data source '''\n",
    "hub = network.hubs['hub']\n",
    "hub.range = DataDict({'thing': {'X': {'min': -2, 'max': 2}, 'Y': {'min': -2, 'max': 2}}})\n",
    "thing = hub.children['thing']\n",
    "state = {'thing': {'X': 0.1, 'Y': .9}}\n",
    "bounds = hub.range.copy()\n",
    "experiment = hub.gaussian\n",
    "params = {'sigma_x': 0.3, 'sigma_y': 0.8, 'x0': 0.3, 'y0': 0.6, 'noise':0.0}\n",
    "source = Source(state, bounds, experiment, params)\n",
    "\n",
    "''' Declare and run pipeline.  Allowed blocks are:\n",
    "    Sampling methods: GridSearch, DifferentialEvolution, ParticleSwarm\n",
    "    Models: GaussianModel\n",
    "    Other: Rescale '''\n",
    "pipe = Pipeline(state, network, source=source)\n",
    "\n",
    "# pipe.add(LBFGSB())\n",
    "# pipe.add(GridSearch(params={'Steps': 10}))\n",
    "# pipe.add(Rescale(threshold=0.75))\n",
    "\n",
    "pipe.add(ParticleSwarm({'Inertia': 0.3, 'Cognitive acceleration': 1, 'Social acceleration': 1}))\n",
    "# pipe.add(DifferentialEvolution())\n",
    "\n",
    "# pipe.add(GridSearch(params={'Steps':10}))\n",
    "pipe.add(GaussianModel(optimizer = DifferentialEvolution()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "points, costs = pipe.run()\n",
    "pipe.plot()\n",
    "print(points[-1], costs[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "After running a pipeline, we can call the pipe.plot() method to generate a plotting widget on the Dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting socketIO client.\n",
      "INFO:root:Starting socketIO client.\n"
     ]
    }
   ],
   "source": [
    "    def plot(self):\n",
    "        # x = self.points[:,0]\n",
    "#         x = None\n",
    "#         y = self.costs\n",
    "#         data = {'y': y.tolist()}\n",
    "#         data['x'] = x\n",
    "#         if x is not None:\n",
    "#             data['x'] =  data['x'].tolist()\n",
    "#         data['labels'] = {'left': 'y', 'bottom': 'X'}\n",
    "#         data = {'data': data, 'data2': data}\n",
    "#         self.network.emit('plot_tabs', data)\n",
    "        \n",
    "        tabs = {}\n",
    "        \n",
    "        tabs['Optimization'] = {'x': None, 'y': self.costs.tolist(), 'labels': {'bottom': 'Iterations', 'left': 'Result'}}\n",
    "        tabs['Data'] = {'points': points.tolist(), 'costs': costs.tolist()}\n",
    "        self.network.emit('plot_tabs', tabs)\n",
    "pipe.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=pipe\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "# seaborn.set()\n",
    "plt.plot(self.costs, '.k')\n",
    "plt.plot(np.minimum.accumulate(self.costs), '--k')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,100)\n",
    "y = np.linspace(0,1,100)\n",
    "predict_points = np.transpose(np.meshgrid(x,y)).reshape(-1, 2)\n",
    "len(predict_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.emit('test', {'name': 'ParticleSwarm'})\n",
    "network.emit('test', {'name': 'DifferentialEvolution'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting socketIO client.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "module = getattr(importlib.import_module('emergent.pipeline'), 'GridSearch')\n",
    "module().params['Steps'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watchdogs\n",
    "The Watchdog class is a modular monitoring unit which periodically runs one experiment and compares the result against a defined threshold. Thresholds are defined with a tuple of the lower and upper bound; passing None to either element will deactivate that bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emergent.monitor import Watchdog\n",
    "\n",
    "def experiment():\n",
    "    return 2\n",
    "\n",
    "params = {}\n",
    "w = Watchdog(experiment=experiment, threshold=(0, 1), name='MyWatchdog')\n",
    "w.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check() method returns a tuple consisting of the measured value and the result of the logical comparison to the specified thresholds.\n",
    "\n",
    "When a check fails, the Watchdog calls its react() method. By default, this method simply returns a null result, but you can implement any custom functionality to respond to problems with monitored variables. For example, let's reimplement w.react() to print a big warning message when the check fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning():\n",
    "    print('WARNING: Watchdog variable out of range!!')\n",
    "    \n",
    "w.react = warning\n",
    "w.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical implementation of a Watchdog-based monitoring system in the lab will probably involve passing ADC read methods to the Watchdog.experiment attribute. For example, suppose the function read_ADC(ch) reads a channel labeled by the integer 'ch' (we'll return dummy values of 0 and 2 instead):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ADC(ch):\n",
    "    return [0.5, 2][ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor both channels, we would simply create two Watchdog objects, each pointing at a given channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, partialmethod\n",
    "watchdogs = {}\n",
    "for ch in range(2):\n",
    "    func = partial(read_ADC, ch)\n",
    "    watchdogs[ch] = Watchdog(func, threshold=(0,1))\n",
    "\n",
    "print(watchdogs[0].check())\n",
    "print(watchdogs[1].check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitors\n",
    "The Monitor class manages multiple Watchdogs. We'll use it to handle the two objects defined in the previous example. If a filename is passed to the Monitor constructor, the result will automatically be appended to the file in a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emergent.monitor import Monitor\n",
    "        \n",
    "        \n",
    "m = Monitor(watchdogs, filename = 'watchdog_test.txt')\n",
    "m.check()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous periodic monitoring, call the Monitor.start_periodic() method with your desired period. For example, let's check once per second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.start_periodic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Monitor.start_periodic method uses Python's sched module for event scheduling to avoid accumulated drifts. For example, if your check() method takes 50 ms to return and you call it in a loop with a 1s delay, the true time between checks will actually be 1.05 s. Using the scheduler allows drift-free checking; however, you should make sure that the check() call always returns in a time shorter than your chosen period!\n",
    "\n",
    "To stop the monitoring, just call the Monitor.stop() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring can be synced to some other process through software triggers, e.g. TTL pulses acquired with a DAQ board. Just define a method which returns as soon as a trigger is received and pass it into the Monitor.start_triggered() method. Let's simulate a trigger arriving once per second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def trigger():\n",
    "    time.sleep(1)\n",
    "    return\n",
    "\n",
    "m.start_triggered(trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples above show how to use the monitor module as a standalone system. Now we will see how to use it in a more powerful context - to watch important signals in your experiment and trigger optimizations if they exit a defined range. First, let's boot up the Core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robbiefasano/emergent/emergent\n",
      "Overwriting /Users/robbiefasano/emergent/emergent/networks/test/devices/test_device.py\n",
      "Overwriting /Users/robbiefasano/emergent/emergent/networks/test/hubs/test_hub.py\n",
      "Overwriting /Users/robbiefasano/emergent/emergent/networks/test/network.py\n",
      "API running at 127.0.0.1:6000\n",
      "DataDict([('device', {'X': 1, 'Y': 2})])\n",
      "New state: DataDict([('device', {'X': 1, 'Y': 2})])\n",
      " * Serving Flask app \"emergent.API.API\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      "EMERGENT API\n"
     ]
    }
   ],
   "source": [
    "%run \"./core.ipynb\"\n",
    "import requests\n",
    "base_url = 'http://localhost:6000'\n",
    "while True:\n",
    "    try:\n",
    "        r=requests.get(base_url)\n",
    "        if r.text == 'EMERGENT API':\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a watchdog and a monitor to check the result of the \"gaussian\" experiment attached to the hub. We'll also set up a very simple optimization pipeline to handle this (more sophisticated examples are shown in the Optimize tutorial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emergent.monitor import Watchdog, Monitor\n",
    "hub = core.hubs['hub']\n",
    "experiment = lambda: -hub.gaussian()\n",
    "w = Watchdog(experiment=experiment, threshold=(0.5, 1), name='gaussian')\n",
    "\n",
    "from emergent.pipeline import *\n",
    "import logging as log\n",
    "def reoptimize(monitor, watchdog, experiment, hub):\n",
    "    log.warning('Signal below threshold - running optimization')\n",
    "    monitor.stop()     # pause monitoring while reoptimizing\n",
    "    state = {'device': hub.state['device']}\n",
    "    bounds = {'device': {'X': (0,1), 'Y': (0,1)}}\n",
    "    pipe = Pipeline(state, bounds, experiment)\n",
    "    pipe.add(LBFGSB())\n",
    "    points, costs = pipe.run()\n",
    "    monitor.start_periodic(1)     # restart monitoring\n",
    "\n",
    "m = Monitor({'gaussian': w}, filename = 'watchdog_test.txt')\n",
    "w.react = lambda: reoptimize(m, w, hub.gaussian, hub)\n",
    "\n",
    "hub.actuate({'device': {'X':0.3, 'Y':0.6}})     # set the initial state to the global optimum\n",
    "\n",
    "m.start_periodic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not familiar with Python's lambda, it allows you define functions in single lines, but defer the execution until the lambda is called - here, we define \"experiment\" as a method which executes the gaussian experiment and returns the opposite sign.\n",
    "\n",
    "Since we set the initial state to the point which optimizes the gaussian cost function, the monitor is perfectly happy. But watch what happens if we move it away (which would also happen if some experimental drift compromised the signal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Signal below threshold - running optimization\n",
      "INFO:root:Optimization complete!\n",
      "INFO:root:Time: 0s\n",
      "INFO:root:Evaluations: 19\n",
      "INFO:root:Initial cost: -0.367879\n",
      "INFO:root:Final cost: -1.000000\n",
      "INFO:root:Improvement: 171.8%\n"
     ]
    }
   ],
   "source": [
    "hub.actuate({'device': {'X':0.0, 'Y':0.6}})     # set the initial state to the global optimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDict([('device', {'X': 0.3000249772106291, 'Y': 0.600000008163276})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we degraded the signal by moving the X degree of freedom away from the optimal point, the monitor automatically reoptimized and returned to near the best point! So now you have a system which actively tries to return to its state of best performance - even if you intentionally turn a knob away from this point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
